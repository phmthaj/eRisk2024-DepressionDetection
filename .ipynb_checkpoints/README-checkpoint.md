# ğŸ§  Depression Detection â€“ eRisk 2024 Task 1

![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?logo=pytorch&logoColor=white)
![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python)
![Status](https://img.shields.io/badge/status-active-success)
![License](https://img.shields.io/badge/license-MIT-green)

---

## ğŸ“Œ Overview
This repository implements a **text classification system** for **CLEF eRisk 2024 â€“ Task 1: Search for Symptoms of Depression**.  

The goal of Task 1 is to determine whether a given **text segment** (sentence) is **relevant** to a specific **depression symptom** (query), based on the 21 symptoms from the **BDI-II questionnaire**.

---

## ğŸ“‚ Project Structure
```
â”œâ”€â”€ data/                # Datasets
â”‚   â”œâ”€â”€ dataset2024.csv  # Final processed dataset (~15k samples)
â”‚   â””â”€â”€ majority_erisk_2024.csv  # Original labels
â”œâ”€â”€ models/              # Saved checkpoints
â”œâ”€â”€ notebooks/           # Experiments & analysis
â”œâ”€â”€ src/                 # Source code
â”‚   â”œâ”€â”€ dataset.py       # Dataset class & DataLoader
â”‚   â”œâ”€â”€ model.py         # LSTM + Attention model
â”‚   â”œâ”€â”€ train.py         # Training pipeline
â”‚   â”œâ”€â”€ evaluate.py      # Evaluation metrics
â”‚   â””â”€â”€ utils.py         # Preprocessing utilities
â””â”€â”€ README.md
```

---

## ğŸ“‚ Dataset
- **Source**: [eRisk 2024 official data](https://drive.google.com/drive/folders/13SVrWMuZxyqLjPFREkNJO3seB_SYYjFS)  
- **Processing Steps**:
  - Extracted sentences and queries from TREC files  
  - Merged judgments from `majority_erisk_2024.csv`  
  - Final dataset: `dataset2024.csv` with ~15,000 labeled samples  

**Label Meaning**:  
- `1` â†’ Sentence expresses symptom (relevant)  
- `0` â†’ Sentence not related (irrelevant)  

---

## ğŸ§¹ Preprocessing
Before training, text samples are normalized with:
- Lowercasing (`text.lower()`)
- Contraction expansion (e.g., *"can't"* â†’ *"cannot"*)  
- Lemmatization (words reduced to their base form)  
- Tokenization (split into word tokens)  

---

## ğŸ—ï¸ Model
The classification model is based on **LSTM with Attention**:

- **Embedding Layer** â†’ transforms tokens into dense vectors  
- **BiLSTM Encoder** â†’ captures contextual information  
- **Attention Mechanism** â†’ focuses on words most relevant to the query  
- **Classifier** â†’ outputs relevance score (`0/1`)  

---

## âš™ï¸ Installation
```bash
# Clone repository
git clone https://github.com/yourname/depression-detection-erisk2024.git
cd depression-detection-erisk2024

# Create environment
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate    # Windows

# Install requirements
pip install -r requirements.txt
```

---

## ğŸš€ Training & Evaluation

### Training
```bash
python src/train.py --data data/dataset2024.csv --epochs 20 --batch_size 64 --lr 1e-3
```

### Evaluation
```bash
python src/evaluate.py --model models/bilstm_attention.pt
```

### Prediction
```python
from src.model import BiLSTMWithAttention
from src.utils import predict_one

print(predict_one("I feel so empty and hopeless..."))
# Output: 1 (relevant to depression symptom)
```

---

## ğŸ“Š Results (Example)
| Model              | Accuracy | F1-score | MAP  |
|--------------------|----------|----------|------|
| BiLSTM             | 0.82     | 0.80     | 0.74 |
| BiLSTM + Attention | 0.85     | 0.83     | 0.78 |

---

## ğŸ“š References
- [CLEF eRisk 2024 Lab Notebook](https://ceur-ws.org/Vol-3740/paper-72.pdf)  
- [Attention Is All You Need (Vaswani et al., 2017)](https://arxiv.org/abs/1706.03762)  
- [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)  

---

## ğŸ“œ License
This project is licensed under the MIT License.
